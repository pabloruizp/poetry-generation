{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PoetryGeneratorCharLevel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6aMhwjwMO8My"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AK4EfqoeAaa"
      },
      "source": [
        "### Info üíº"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsydFfIVeXsp"
      },
      "source": [
        "*Dataset*    \r\n",
        "https://www.kaggle.com/andreamorgar/spanish-poetry-dataset\r\n",
        "\r\n",
        "<br>\r\n",
        "\r\n",
        "*Links to check*  \r\n",
        "https://www.kaggle.com/shivamb/beginners-guide-to-text-generation-using-lstms  \r\n",
        "https://www.tensorflow.org/tutorials/text/text_generation  \r\n",
        "https://towardsdatascience.com/creating-poems-from-ones-own-poems-neural-networks-and-life-paradoxes-a9cffd2b07e3  \r\n",
        "https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aMhwjwMO8My"
      },
      "source": [
        "### Text Prepocessing üìñ\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbIemlrgFAol"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKLsg6hqG-dh"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "table = pd.read_csv('./gdrive/MyDrive/ColabNotebooks/Text/PoetryGenerator/poems.csv')\r\n",
        "table.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VENrk0c2IRJs"
      },
      "source": [
        "poems = table['content'].to_list()\r\n",
        "len(poems)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui8yRqSBKLqL"
      },
      "source": [
        "print(poems[0][:600])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk42A6B6Bxgd"
      },
      "source": [
        "poems = [str(poem) for poem in poems]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heoKkGiPHLKp"
      },
      "source": [
        "import unicodedata\r\n",
        "import re\r\n",
        "def strip_accents(s):\r\n",
        "   return ''.join(c for c in unicodedata.normalize('NFD', s)\r\n",
        "                  if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21Uo4da3RIBy"
      },
      "source": [
        "poems = [re.sub(r'[\\t\\x85\\x91\\x92\\x93\\x94\\x96\\x97¬®¬´¬¥¬∑¬ª‚Äï\\uf0bc]', '',str(poem)) for poem in poems]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OAcMDekDhOm"
      },
      "source": [
        "poemsText = ''.join(poems)\r\n",
        "# The unique characters in the file\r\n",
        "vocab = sorted(set(poemsText))\r\n",
        "print('{} unique characters'.format(len(vocab)))\r\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1IPXMCsnDnn"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5pQS1VTnd_l"
      },
      "source": [
        "char2id = preprocessing.StringLookup(vocabulary=list(vocab))\r\n",
        "id2char = preprocessing.StringLookup(vocabulary=char2id.get_vocabulary(), invert=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZUwxqybo--y"
      },
      "source": [
        "poemsIDs = char2id([char for char in poemsText])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjjcJi7kpiLI"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(poemsIDs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ6tx7UDqfWf"
      },
      "source": [
        "seqLen = 100\r\n",
        "datasetBatches = dataset.batch(seqLen+1, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNaSksNYq-QI"
      },
      "source": [
        "datasetBatches.take(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwFIXYuAq0hz"
      },
      "source": [
        "def createTrainingPredictions(seq):\r\n",
        "  x = seq[:-1]\r\n",
        "  y = seq[1:]\r\n",
        "  return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmHedXR4rqX9"
      },
      "source": [
        "dataset = datasetBatches.map(createTrainingPredictions)\r\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCknqW3EsIw9"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "BUFFER_SIZE = 10000\r\n",
        "\r\n",
        "dataset = (dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE))\r\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGNu_Ti1PX-b"
      },
      "source": [
        "### Model üß†"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH8Zut0fs7JX"
      },
      "source": [
        "vocab_size = len(vocab)\r\n",
        "embedding_dim = 256\r\n",
        "rnn_units = 1024\r\n",
        "\r\n",
        "class PoetryGeneratorModel(tf.keras.Model):\r\n",
        "  def __init__(self, vocab_size, embeding_dim, rnn_units):\r\n",
        "    super().__init__(self)\r\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embeding_dim)\r\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\r\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\r\n",
        "\r\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\r\n",
        "    x = inputs\r\n",
        "    x = self.embedding(x, training=training)\r\n",
        "    if states is None:\r\n",
        "      states = self.gru.get_initial_state(x)\r\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\r\n",
        "    x = self.dense(x, training=training)\r\n",
        "\r\n",
        "    if return_state:\r\n",
        "      return x, states\r\n",
        "    else:\r\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO9zVTZg6Lwg"
      },
      "source": [
        "model = PoetryGeneratorModel(vocab_size=len(char2id.get_vocabulary()), embeding_dim=embedding_dim,rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hhn2jdF6oPu"
      },
      "source": [
        "model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0gXn8fm6w9o"
      },
      "source": [
        "model.fit(dataset, epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcYkNuQxXkqL"
      },
      "source": [
        "model.save_weights('poeta.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IySK-vOVl95E"
      },
      "source": [
        "### Text Generation ‚úçüèª"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcEhn1NKltSA"
      },
      "source": [
        "initial = ['S']\r\n",
        "initial = [char for char in initial]\r\n",
        "initialIDs = char2id(initial)\r\n",
        "initialIDs = tf.expand_dims(initialIDs, axis=0)\r\n",
        "model(initialIDs, states=None, return_state=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl1Ml1ZaTqUt"
      },
      "source": [
        "poeta  = model\r\n",
        "poeta.load_weights('poeta.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PaAJjCzL7tX"
      },
      "source": [
        "def generateText(model, nChars, initialString):\r\n",
        "  states = None\r\n",
        "  initial = [initialString]\r\n",
        "  poem = initial[0]\r\n",
        "\r\n",
        "  for i in range(nChars):\r\n",
        "    initial = [char for char in initial]\r\n",
        "    initialIDs = char2id(initial)\r\n",
        "    initialIDs = tf.expand_dims(initialIDs, axis=0)\r\n",
        "    pred, states = model(initialIDs, states=states, return_state=True)\r\n",
        "    pred = pred[:, -1, :]\r\n",
        "    pred = tf.random.categorical(pred, num_samples=1)\r\n",
        "    pred = tf.squeeze(pred, axis=-1)\r\n",
        "    initial = id2char(pred)\r\n",
        "    poem += id2char(pred)[0].numpy().decode('utf-8')\r\n",
        "\r\n",
        "  poem = poem.split('\\n')\r\n",
        "  poem = '\\n'.join([line.strip() for line in poem])\r\n",
        "  poem = re.sub(' +', ' ', poem)\r\n",
        "  print(poem, '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUyKSf4KL2Pc"
      },
      "source": [
        "generateText(poeta, 500, 'E')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}